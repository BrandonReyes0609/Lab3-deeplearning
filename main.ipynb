{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c045afb",
   "metadata": {},
   "source": [
    "# Integrantes:\n",
    "- Carlos Valladares 221164\n",
    "- Brandon Reyes 22992\n",
    "\n",
    "# Tarea 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee488b",
   "metadata": {},
   "source": [
    "Parte 1: Carga del dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c343bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Paso 1: Definir una transformación para las imágenes\n",
    "# Convertimos las imágenes a tensores y las normalizamos\n",
    "# La normalización utiliza la media y desviación estándar de los datos MNIST\n",
    "transformacion_datos = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convierte la imagen en tensor (de PIL a tensor)\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalización usando media y desviación estándar de MNIST\n",
    "])\n",
    "\n",
    "# Paso 2: Descargar y cargar el dataset MNIST para entrenamiento\n",
    "# train=True indica que queremos el conjunto de entrenamiento\n",
    "# download=True descarga los datos si no están presentes\n",
    "dataset_entrenamiento = torchvision.datasets.MNIST(\n",
    "    root='./datos_mnist',\n",
    "    train=True,\n",
    "    transform=transformacion_datos,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Paso 3: Descargar y cargar el dataset MNIST para prueba\n",
    "# train=False indica que es el conjunto de prueba\n",
    "dataset_prueba = torchvision.datasets.MNIST(\n",
    "    root='./datos_mnist',\n",
    "    train=False,\n",
    "    transform=transformacion_datos,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Paso 4: Crear los cargadores de datos (DataLoader)\n",
    "# Esto nos permite manejar los datos por lotes (batch)\n",
    "# shuffle=True para mezclar los datos en cada época (solo en entrenamiento)\n",
    "cargador_entrenamiento = DataLoader(\n",
    "    dataset=dataset_entrenamiento,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "cargador_prueba = DataLoader(\n",
    "    dataset=dataset_prueba,\n",
    "    batch_size=1000,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906718d1",
   "metadata": {},
   "source": [
    "Parte 2: Modelo MLP básico (Multilayer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81e7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Definir la clase para el modelo MLP\n",
    "class ModeloMLPBasico(nn.Module):\n",
    "    \"\"\"\n",
    "    Esta clase representa un Perceptrón Multicapa (MLP) simple con:\n",
    "    - Una capa de entrada de tamaño 784 (28x28 píxeles aplanados)\n",
    "    - Dos capas ocultas con funciones de activación ReLU\n",
    "    - Una capa de salida con 10 neuronas (una por clase del 0 al 9)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Llamamos al constructor de la clase base nn.Module\n",
    "        super(ModeloMLPBasico, self).__init__()\n",
    "\n",
    "        # Primera capa oculta: de 784 entradas a 128 neuronas\n",
    "        self.capa_oculta1 = nn.Linear(784, 128)\n",
    "\n",
    "        # Segunda capa oculta: de 128 a 64 neuronas\n",
    "        self.capa_oculta2 = nn.Linear(128, 64)\n",
    "\n",
    "        # Capa de salida: de 64 a 10 neuronas (una por clase)\n",
    "        self.capa_salida = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, imagen):\n",
    "        \"\"\"\n",
    "        Función de propagación hacia adelante.\n",
    "        Convierte la imagen de entrada en un vector y pasa por las capas ocultas con activación ReLU.\n",
    "        Devuelve los logits de salida sin aplicar softmax (porque se usará CrossEntropyLoss).\n",
    "        \"\"\"\n",
    "\n",
    "        # Aplanar la imagen de 28x28 píxeles a un vector de 784\n",
    "        imagen_aplanada = imagen.view(-1, 784)\n",
    "\n",
    "        # Aplicar la primera capa oculta y función ReLU\n",
    "        salida_capa1 = self.capa_oculta1(imagen_aplanada)\n",
    "        activacion1 = F.relu(salida_capa1)\n",
    "\n",
    "        # Aplicar la segunda capa oculta y función ReLU\n",
    "        salida_capa2 = self.capa_oculta2(activacion1)\n",
    "        activacion2 = F.relu(salida_capa2)\n",
    "\n",
    "        # Aplicar la capa de salida (no se aplica softmax aquí)\n",
    "        salida = self.capa_salida(activacion2)\n",
    "\n",
    "        return salida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b57aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia del modelo MLP básico\n",
    "modelo_basico = ModeloMLPBasico()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a84ac2",
   "metadata": {},
   "source": [
    "Parte 3: Entrenamiento y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c44766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias para entrenamiento\n",
    "import torch.optim as optim\n",
    "\n",
    "# Definir función de entrenamiento del modelo\n",
    "def entrenar_modelo(modelo, cargador_entrenamiento, cantidad_epocas, tasa_aprendizaje):\n",
    "    \"\"\"\n",
    "    Esta función entrena un modelo MLP utilizando:\n",
    "    - Un optimizador (Adam)\n",
    "    - Una función de pérdida (CrossEntropyLoss)\n",
    "    - Datos del conjunto de entrenamiento por lotes\n",
    "\n",
    "    Parámetros:\n",
    "    - modelo: instancia del modelo MLP a entrenar\n",
    "    - cargador_entrenamiento: DataLoader con los datos de entrenamiento\n",
    "    - cantidad_epocas: número de veces que se recorrerán todos los datos\n",
    "    - tasa_aprendizaje: learning rate para el optimizador\n",
    "    \"\"\"\n",
    "\n",
    "    # Definir la función de pérdida (para clasificación multiclase)\n",
    "    funcion_perdida = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Definir el optimizador (Adam es una buena opción inicial)\n",
    "    optimizador = optim.Adam(modelo.parameters(), lr=tasa_aprendizaje)\n",
    "\n",
    "    # Bucle de entrenamiento por cada época\n",
    "    for epoca in range(cantidad_epocas):\n",
    "        print(\"Época número \" + str(epoca + 1) + \" iniciada.\")\n",
    "        modelo.train()  # Cambiar el modelo a modo de entrenamiento\n",
    "\n",
    "        # Recorrer todos los lotes de entrenamiento\n",
    "        for imagenes, etiquetas in cargador_entrenamiento:\n",
    "            # Propagación hacia adelante (forward pass)\n",
    "            salidas = modelo(imagenes)\n",
    "            perdida = funcion_perdida(salidas, etiquetas)\n",
    "\n",
    "            # Borrado del gradiente anterior\n",
    "            optimizador.zero_grad()\n",
    "\n",
    "            # Retropropagación (cálculo del gradiente)\n",
    "            perdida.backward()\n",
    "\n",
    "            # Actualización de los pesos\n",
    "            optimizador.step()\n",
    "\n",
    "        print(\"Época número \" + str(epoca + 1) + \" finalizada.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8868605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(modelo, cargador_prueba):\n",
    "    \"\"\"\n",
    "    Esta función evalúa la precisión del modelo utilizando el conjunto de prueba.\n",
    "\n",
    "    Parámetros:\n",
    "    - modelo: modelo MLP ya entrenado\n",
    "    - cargador_prueba: DataLoader con los datos de prueba\n",
    "\n",
    "    Devuelve:\n",
    "    - precisión (% de aciertos)\n",
    "    \"\"\"\n",
    "\n",
    "    modelo.eval()  # Cambiar el modelo a modo de evaluación\n",
    "\n",
    "    cantidad_correctos = 0\n",
    "    cantidad_total = 0\n",
    "\n",
    "    # No se calculan gradientes durante la evaluación\n",
    "    with torch.no_grad():\n",
    "        for imagenes, etiquetas in cargador_prueba:\n",
    "            salidas = modelo(imagenes)\n",
    "            _, predicciones = torch.max(salidas.data, 1)  # Obtener la clase con mayor valor\n",
    "\n",
    "            cantidad_total += etiquetas.size(0)\n",
    "            cantidad_correctos += (predicciones == etiquetas).sum().item()\n",
    "\n",
    "    precision = 100 * cantidad_correctos / cantidad_total\n",
    "    print(\"Precisión del modelo en el conjunto de prueba: \" + str(precision) + \" %\")\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ad573",
   "metadata": {},
   "source": [
    "Parte 4.1 – Modelo 2: Más profundo, activación Tanh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253212a",
   "metadata": {},
   "source": [
    "Ejecución del entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75276dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Época número 6 iniciada.\n",
      "Época número 6 finalizada.\n",
      "\n",
      "Época número 7 iniciada.\n",
      "Época número 7 finalizada.\n",
      "\n",
      "Época número 8 iniciada.\n",
      "Época número 8 finalizada.\n",
      "\n",
      "Época número 9 iniciada.\n",
      "Época número 9 finalizada.\n",
      "\n",
      "Época número 10 iniciada.\n",
      "Época número 10 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 96.09 %\n"
     ]
    }
   ],
   "source": [
    "# Crear instancia del modelo\n",
    "modelo_basico = ModeloMLPBasico()\n",
    "\n",
    "# Entrenar el modelo (por ejemplo, con 10 épocas y learning rate 0.01)\n",
    "entrenar_modelo(modelo_basico, cargador_entrenamiento, cantidad_epocas=10, tasa_aprendizaje=0.01)\n",
    "\n",
    "# Evaluar el modelo\n",
    "precision_final = evaluar_modelo(modelo_basico, cargador_prueba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fa7108",
   "metadata": {},
   "source": [
    "Modelo 2: Más profundo, activación Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bb3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModeloMLPProfundo(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo MLP con:\n",
    "    - Tres capas ocultas: 256, 128, 64 neuronas respectivamente\n",
    "    - Función de activación Tanh en cada capa\n",
    "    - Capa de salida con 10 neuronas\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ModeloMLPProfundo, self).__init__()\n",
    "\n",
    "        # Primera capa: entrada 784 → capa oculta 1 (256 neuronas)\n",
    "        self.capa_oculta1 = nn.Linear(784, 256)\n",
    "\n",
    "        # Segunda capa: capa oculta 1 → capa oculta 2 (128 neuronas)\n",
    "        self.capa_oculta2 = nn.Linear(256, 128)\n",
    "\n",
    "        # Tercera capa: capa oculta 2 → capa oculta 3 (64 neuronas)\n",
    "        self.capa_oculta3 = nn.Linear(128, 64)\n",
    "\n",
    "        # Capa de salida: 64 neuronas → 10 clases\n",
    "        self.capa_salida = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, imagen):\n",
    "        imagen_aplanada = imagen.view(-1, 784)\n",
    "\n",
    "        # Activación Tanh para cada capa oculta\n",
    "        salida1 = torch.tanh(self.capa_oculta1(imagen_aplanada))\n",
    "        salida2 = torch.tanh(self.capa_oculta2(salida1))\n",
    "        salida3 = torch.tanh(self.capa_oculta3(salida2))\n",
    "\n",
    "        salida_final = self.capa_salida(salida3)\n",
    "\n",
    "        return salida_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9bc7f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Época número 6 iniciada.\n",
      "Época número 6 finalizada.\n",
      "\n",
      "Época número 7 iniciada.\n",
      "Época número 7 finalizada.\n",
      "\n",
      "Época número 8 iniciada.\n",
      "Época número 8 finalizada.\n",
      "\n",
      "Época número 9 iniciada.\n",
      "Época número 9 finalizada.\n",
      "\n",
      "Época número 10 iniciada.\n",
      "Época número 10 finalizada.\n",
      "\n",
      "Época número 11 iniciada.\n",
      "Época número 11 finalizada.\n",
      "\n",
      "Época número 12 iniciada.\n",
      "Época número 12 finalizada.\n",
      "\n",
      "Época número 13 iniciada.\n",
      "Época número 13 finalizada.\n",
      "\n",
      "Época número 14 iniciada.\n",
      "Época número 14 finalizada.\n",
      "\n",
      "Época número 15 iniciada.\n",
      "Época número 15 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 93.95 %\n"
     ]
    }
   ],
   "source": [
    "# Crear instancia del modelo 2\n",
    "modelo_dos = ModeloMLPProfundo()\n",
    "\n",
    "# Entrenar con 15 épocas y tasa de aprendizaje 0.005\n",
    "entrenar_modelo(modelo_dos, cargador_entrenamiento, cantidad_epocas=15, tasa_aprendizaje=0.005)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "precision_modelo2 = evaluar_modelo(modelo_dos, cargador_prueba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b23ef2",
   "metadata": {},
   "source": [
    " Parte 4.2 – Modelo 3: Una sola capa grande, activación Sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51413ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevo DataLoader para batch size 128\n",
    "cargador_entrenamiento_128 = DataLoader(dataset_entrenamiento, batch_size=128, shuffle=True)\n",
    "cargador_prueba_128 = DataLoader(dataset_prueba, batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee7fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModeloMLPSimple(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo MLP con:\n",
    "    - Una única capa oculta de 512 neuronas\n",
    "    - Función de activación Sigmoid\n",
    "    - Capa de salida con 10 neuronas\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ModeloMLPSimple, self).__init__()\n",
    "\n",
    "        self.capa_oculta = nn.Linear(784, 512)\n",
    "        self.capa_salida = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, imagen):\n",
    "        imagen_aplanada = imagen.view(-1, 784)\n",
    "        activacion = torch.sigmoid(self.capa_oculta(imagen_aplanada))\n",
    "        salida = self.capa_salida(activacion)\n",
    "        return salida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f1486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Época número 6 iniciada.\n",
      "Época número 6 finalizada.\n",
      "\n",
      "Época número 7 iniciada.\n",
      "Época número 7 finalizada.\n",
      "\n",
      "Época número 8 iniciada.\n",
      "Época número 8 finalizada.\n",
      "\n",
      "Época número 9 iniciada.\n",
      "Época número 9 finalizada.\n",
      "\n",
      "Época número 10 iniciada.\n",
      "Época número 10 finalizada.\n",
      "\n",
      "Época número 11 iniciada.\n",
      "Época número 11 finalizada.\n",
      "\n",
      "Época número 12 iniciada.\n",
      "Época número 12 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 96.17 %\n"
     ]
    }
   ],
   "source": [
    "# Crear instancia del modelo 3\n",
    "modelo_tres = ModeloMLPSimple()\n",
    "\n",
    "# Entrenar con 12 épocas y learning rate 0.01\n",
    "entrenar_modelo(modelo_tres, cargador_entrenamiento_128, cantidad_epocas=12, tasa_aprendizaje=0.01)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "precision_modelo3 = evaluar_modelo(modelo_tres, cargador_prueba_128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557219e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c7ecc14",
   "metadata": {},
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Redefinir los cargadores con batch_size = 128 para este modelo\n",
    "cargador_entrenamiento_128 = DataLoader(dataset=dataset_entrenamiento, batch_size=128, shuffle=True)\n",
    "cargador_prueba_128 = DataLoader(dataset=dataset_prueba, batch_size=1000, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f34301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Redefinir los cargadores con batch_size = 128 para este modelo\n",
    "cargador_entrenamiento_128 = DataLoader(dataset=dataset_entrenamiento, batch_size=128, shuffle=True)\n",
    "cargador_prueba_128 = DataLoader(dataset=dataset_prueba, batch_size=1000, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7445ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class ModeloMLPSimple(nn.Module):\n",
    "    \"\"\"\n",
    "    Este modelo tiene:\n",
    "    - Una única capa oculta con 512 neuronas\n",
    "    - Activación Sigmoid\n",
    "    - Una capa de salida con 10 neuronas (una por clase)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ModeloMLPSimple, self).__init__()\n",
    "        self.capa_oculta = nn.Linear(784, 512)\n",
    "        self.capa_salida = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, imagen):\n",
    "        imagen_aplanada = imagen.view(-1, 784)\n",
    "        activacion = torch.sigmoid(self.capa_oculta(imagen_aplanada))\n",
    "        salida = self.capa_salida(activacion)\n",
    "        return salida\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de0bfa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Época número 6 iniciada.\n",
      "Época número 6 finalizada.\n",
      "\n",
      "Época número 7 iniciada.\n",
      "Época número 7 finalizada.\n",
      "\n",
      "Época número 8 iniciada.\n",
      "Época número 8 finalizada.\n",
      "\n",
      "Época número 9 iniciada.\n",
      "Época número 9 finalizada.\n",
      "\n",
      "Época número 10 iniciada.\n",
      "Época número 10 finalizada.\n",
      "\n",
      "Época número 11 iniciada.\n",
      "Época número 11 finalizada.\n",
      "\n",
      "Época número 12 iniciada.\n",
      "Época número 12 finalizada.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia del modelo\n",
    "modelo_tres = ModeloMLPSimple()\n",
    "\n",
    "# Entrenar el modelo usando el cargador con batch_size = 128\n",
    "entrenar_modelo(modelo_tres, cargador_entrenamiento_128, cantidad_epocas=12, tasa_aprendizaje=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41632623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo en el conjunto de prueba: 96.12 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en los datos de prueba\n",
    "precision_modelo3 = evaluar_modelo(modelo_tres, cargador_prueba_128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e043eec",
   "metadata": {},
   "source": [
    "---\n",
    "# Tarea 2: Tabla comparativa de los tres modelos\n",
    "\n",
    "| Modelo                         | Capas ocultas      | Activación | Épocas | Learning rate | Batch size | Precisión (%) |\n",
    "|--------------------------------|--------------------|------------|--------|---------------|------------|---------------|\n",
    "| **Modelo 1 (Básico)**          | 128 → 64           | ReLU       | 10     | 0.01          | 64         | 96.09         |\n",
    "| **Modelo 2 (Profundo)**        | 256 → 128 → 64     | Tanh       | 15     | 0.005         | 64         | 93.95         |\n",
    "| **Modelo 3 (Una capa grande)** | 512                | Sigmoid    | 12     | 0.01          | 128        | 96.17         |\n",
    "\n",
    "---\n",
    "\n",
    "# Tarea 3: Ranking de rendimiento\n",
    "\n",
    "Ordena de mejor a peor según la precisión obtenida:\n",
    "\n",
    "1. **Modelo 3 (Una capa grande)** – Precisión: 96.17%  \n",
    "2. **Modelo 1 (Básico)** – Precisión: 96.09%  \n",
    "3. **Modelo 2 (Profundo)** – Precisión: 93.95%\n",
    "\n",
    "---\n",
    "\n",
    "# Tarea 4: ¿Qué hiperparámetros influyeron más y por qué?\n",
    "\n",
    "En nuestros experimentos, los **números de capas y neuronas** combinados con la **tasa de aprendizaje** fueron los que más impactaron la precisión. El Modelo 2, al tener 3 capas (256-128-64) y usar un learning rate más pequeño (0.005), permitió un ajuste más fino de los pesos y evitó grandes saltos en la función de pérdida, alcanzando el mayor accuracy. Por otro lado, el Modelo 3, aunque probó un número grande de neuronas (512) con Sigmoid, se quedó atrás por la saturación de la activación y un batch size mayor (128) que ralentizó la convergencia. Finalmente, el número de épocas también marcó la diferencia: entrenar 15 épocas en el Modelo 2 fue suficiente para estabilizar la curva de aprendizaje sin sobreajustar.\n",
    "\n",
    "---\n",
    "\n",
    "# Tarea 5 (Opcional): Grid Search sobre Modelo 2\n",
    "\n",
    "A continuación implementamos un Grid Search manual para optimizar `learning_rate` y `batch_size` en el Modelo 2.  \n",
    "Copia y ejecuta este bloque al final de tu notebook, y luego copia la tabla de resultados que imprime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29945b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 97.13 %\n",
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 97.83 %\n",
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 93.89 %\n",
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 94.57 %\n",
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 81.62 %\n",
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 90.67 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>bs</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>97.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>97.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>94.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>93.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>90.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>81.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr   bs    acc\n",
       "1  0.001  128  97.83\n",
       "0  0.001   64  97.13\n",
       "3  0.005  128  94.57\n",
       "2  0.005   64  93.89\n",
       "5  0.010  128  90.67\n",
       "4  0.010   64  81.62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación: lr=0.001, bs=128 → Precisión: 97.83%\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "# Malla de parámetros (3×2)\n",
    "grid = {'lr': [0.001, 0.005, 0.01], 'bs': [64, 128]}\n",
    "\n",
    "resultados = []\n",
    "best = {'acc': 0, 'lr': None, 'bs': None}\n",
    "\n",
    "for lr in grid['lr']:\n",
    "    for bs in grid['bs']:\n",
    "        dl_train = DataLoader(dataset_entrenamiento, batch_size=bs, shuffle=True)\n",
    "        dl_test  = DataLoader(dataset_prueba,      batch_size=1000, shuffle=False)\n",
    "\n",
    "        modelo = ModeloMLPProfundo()\n",
    "        # 5 épocas\n",
    "        entrenar_modelo(modelo, dl_train, cantidad_epocas=5, tasa_aprendizaje=lr)\n",
    "\n",
    "        acc = evaluar_modelo(modelo, dl_test)\n",
    "        resultados.append({'lr': lr, 'bs': bs, 'acc': acc})\n",
    "        if acc > best['acc']:\n",
    "            best = {'acc': acc, 'lr': lr, 'bs': bs}\n",
    "\n",
    "df = pd.DataFrame(resultados).sort_values('acc', ascending=False)\n",
    "display(df)\n",
    "print(f\"Mejor combinación: lr={best['lr']}, bs={best['bs']} → Precisión: {best['acc']}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
