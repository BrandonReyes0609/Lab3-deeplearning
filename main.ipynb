{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ee488b",
   "metadata": {},
   "source": [
    "Parte 1: Carga del dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c343bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Paso 1: Definir una transformación para las imágenes\n",
    "# Convertimos las imágenes a tensores y las normalizamos\n",
    "# La normalización utiliza la media y desviación estándar de los datos MNIST\n",
    "transformacion_datos = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convierte la imagen en tensor (de PIL a tensor)\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalización usando media y desviación estándar de MNIST\n",
    "])\n",
    "\n",
    "# Paso 2: Descargar y cargar el dataset MNIST para entrenamiento\n",
    "# train=True indica que queremos el conjunto de entrenamiento\n",
    "# download=True descarga los datos si no están presentes\n",
    "dataset_entrenamiento = torchvision.datasets.MNIST(\n",
    "    root='./datos_mnist',\n",
    "    train=True,\n",
    "    transform=transformacion_datos,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Paso 3: Descargar y cargar el dataset MNIST para prueba\n",
    "# train=False indica que es el conjunto de prueba\n",
    "dataset_prueba = torchvision.datasets.MNIST(\n",
    "    root='./datos_mnist',\n",
    "    train=False,\n",
    "    transform=transformacion_datos,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Paso 4: Crear los cargadores de datos (DataLoader)\n",
    "# Esto nos permite manejar los datos por lotes (batch)\n",
    "# shuffle=True para mezclar los datos en cada época (solo en entrenamiento)\n",
    "cargador_entrenamiento = DataLoader(\n",
    "    dataset=dataset_entrenamiento,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "cargador_prueba = DataLoader(\n",
    "    dataset=dataset_prueba,\n",
    "    batch_size=1000,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906718d1",
   "metadata": {},
   "source": [
    "Parte 2: Modelo MLP básico (Multilayer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81e7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Definir la clase para el modelo MLP\n",
    "class ModeloMLPBasico(nn.Module):\n",
    "    \"\"\"\n",
    "    Esta clase representa un Perceptrón Multicapa (MLP) simple con:\n",
    "    - Una capa de entrada de tamaño 784 (28x28 píxeles aplanados)\n",
    "    - Dos capas ocultas con funciones de activación ReLU\n",
    "    - Una capa de salida con 10 neuronas (una por clase del 0 al 9)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Llamamos al constructor de la clase base nn.Module\n",
    "        super(ModeloMLPBasico, self).__init__()\n",
    "\n",
    "        # Primera capa oculta: de 784 entradas a 128 neuronas\n",
    "        self.capa_oculta1 = nn.Linear(784, 128)\n",
    "\n",
    "        # Segunda capa oculta: de 128 a 64 neuronas\n",
    "        self.capa_oculta2 = nn.Linear(128, 64)\n",
    "\n",
    "        # Capa de salida: de 64 a 10 neuronas (una por clase)\n",
    "        self.capa_salida = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, imagen):\n",
    "        \"\"\"\n",
    "        Función de propagación hacia adelante.\n",
    "        Convierte la imagen de entrada en un vector y pasa por las capas ocultas con activación ReLU.\n",
    "        Devuelve los logits de salida sin aplicar softmax (porque se usará CrossEntropyLoss).\n",
    "        \"\"\"\n",
    "\n",
    "        # Aplanar la imagen de 28x28 píxeles a un vector de 784\n",
    "        imagen_aplanada = imagen.view(-1, 784)\n",
    "\n",
    "        # Aplicar la primera capa oculta y función ReLU\n",
    "        salida_capa1 = self.capa_oculta1(imagen_aplanada)\n",
    "        activacion1 = F.relu(salida_capa1)\n",
    "\n",
    "        # Aplicar la segunda capa oculta y función ReLU\n",
    "        salida_capa2 = self.capa_oculta2(activacion1)\n",
    "        activacion2 = F.relu(salida_capa2)\n",
    "\n",
    "        # Aplicar la capa de salida (no se aplica softmax aquí)\n",
    "        salida = self.capa_salida(activacion2)\n",
    "\n",
    "        return salida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b57aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia del modelo MLP básico\n",
    "modelo_basico = ModeloMLPBasico()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a84ac2",
   "metadata": {},
   "source": [
    "Parte 3: Entrenamiento y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c44766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias para entrenamiento\n",
    "import torch.optim as optim\n",
    "\n",
    "# Definir función de entrenamiento del modelo\n",
    "def entrenar_modelo(modelo, cargador_entrenamiento, cantidad_epocas, tasa_aprendizaje):\n",
    "    \"\"\"\n",
    "    Esta función entrena un modelo MLP utilizando:\n",
    "    - Un optimizador (Adam)\n",
    "    - Una función de pérdida (CrossEntropyLoss)\n",
    "    - Datos del conjunto de entrenamiento por lotes\n",
    "\n",
    "    Parámetros:\n",
    "    - modelo: instancia del modelo MLP a entrenar\n",
    "    - cargador_entrenamiento: DataLoader con los datos de entrenamiento\n",
    "    - cantidad_epocas: número de veces que se recorrerán todos los datos\n",
    "    - tasa_aprendizaje: learning rate para el optimizador\n",
    "    \"\"\"\n",
    "\n",
    "    # Definir la función de pérdida (para clasificación multiclase)\n",
    "    funcion_perdida = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Definir el optimizador (Adam es una buena opción inicial)\n",
    "    optimizador = optim.Adam(modelo.parameters(), lr=tasa_aprendizaje)\n",
    "\n",
    "    # Bucle de entrenamiento por cada época\n",
    "    for epoca in range(cantidad_epocas):\n",
    "        print(\"Época número \" + str(epoca + 1) + \" iniciada.\")\n",
    "        modelo.train()  # Cambiar el modelo a modo de entrenamiento\n",
    "\n",
    "        # Recorrer todos los lotes de entrenamiento\n",
    "        for imagenes, etiquetas in cargador_entrenamiento:\n",
    "            # Propagación hacia adelante (forward pass)\n",
    "            salidas = modelo(imagenes)\n",
    "            perdida = funcion_perdida(salidas, etiquetas)\n",
    "\n",
    "            # Borrado del gradiente anterior\n",
    "            optimizador.zero_grad()\n",
    "\n",
    "            # Retropropagación (cálculo del gradiente)\n",
    "            perdida.backward()\n",
    "\n",
    "            # Actualización de los pesos\n",
    "            optimizador.step()\n",
    "\n",
    "        print(\"Época número \" + str(epoca + 1) + \" finalizada.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8868605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(modelo, cargador_prueba):\n",
    "    \"\"\"\n",
    "    Esta función evalúa la precisión del modelo utilizando el conjunto de prueba.\n",
    "\n",
    "    Parámetros:\n",
    "    - modelo: modelo MLP ya entrenado\n",
    "    - cargador_prueba: DataLoader con los datos de prueba\n",
    "\n",
    "    Devuelve:\n",
    "    - precisión (% de aciertos)\n",
    "    \"\"\"\n",
    "\n",
    "    modelo.eval()  # Cambiar el modelo a modo de evaluación\n",
    "\n",
    "    cantidad_correctos = 0\n",
    "    cantidad_total = 0\n",
    "\n",
    "    # No se calculan gradientes durante la evaluación\n",
    "    with torch.no_grad():\n",
    "        for imagenes, etiquetas in cargador_prueba:\n",
    "            salidas = modelo(imagenes)\n",
    "            _, predicciones = torch.max(salidas.data, 1)  # Obtener la clase con mayor valor\n",
    "\n",
    "            cantidad_total += etiquetas.size(0)\n",
    "            cantidad_correctos += (predicciones == etiquetas).sum().item()\n",
    "\n",
    "    precision = 100 * cantidad_correctos / cantidad_total\n",
    "    print(\"Precisión del modelo en el conjunto de prueba: \" + str(precision) + \" %\")\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ad573",
   "metadata": {},
   "source": [
    "Parte 4.1 – Modelo 2: Más profundo, activación Tanh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253212a",
   "metadata": {},
   "source": [
    "Ejecución del entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75276dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Época número 6 iniciada.\n",
      "Época número 6 finalizada.\n",
      "\n",
      "Época número 7 iniciada.\n",
      "Época número 7 finalizada.\n",
      "\n",
      "Época número 8 iniciada.\n",
      "Época número 8 finalizada.\n",
      "\n",
      "Época número 9 iniciada.\n",
      "Época número 9 finalizada.\n",
      "\n",
      "Época número 10 iniciada.\n",
      "Época número 10 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 95.98 %\n"
     ]
    }
   ],
   "source": [
    "# Crear instancia del modelo\n",
    "modelo_basico = ModeloMLPBasico()\n",
    "\n",
    "# Entrenar el modelo (por ejemplo, con 10 épocas y learning rate 0.01)\n",
    "entrenar_modelo(modelo_basico, cargador_entrenamiento, cantidad_epocas=10, tasa_aprendizaje=0.01)\n",
    "\n",
    "# Evaluar el modelo\n",
    "precision_final = evaluar_modelo(modelo_basico, cargador_prueba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fa7108",
   "metadata": {},
   "source": [
    "Modelo 2: Más profundo, activación Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5bb3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModeloMLPProfundo(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo MLP con:\n",
    "    - Tres capas ocultas: 256, 128, 64 neuronas respectivamente\n",
    "    - Función de activación Tanh en cada capa\n",
    "    - Capa de salida con 10 neuronas\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ModeloMLPProfundo, self).__init__()\n",
    "\n",
    "        # Primera capa: entrada 784 → capa oculta 1 (256 neuronas)\n",
    "        self.capa_oculta1 = nn.Linear(784, 256)\n",
    "\n",
    "        # Segunda capa: capa oculta 1 → capa oculta 2 (128 neuronas)\n",
    "        self.capa_oculta2 = nn.Linear(256, 128)\n",
    "\n",
    "        # Tercera capa: capa oculta 2 → capa oculta 3 (64 neuronas)\n",
    "        self.capa_oculta3 = nn.Linear(128, 64)\n",
    "\n",
    "        # Capa de salida: 64 neuronas → 10 clases\n",
    "        self.capa_salida = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, imagen):\n",
    "        imagen_aplanada = imagen.view(-1, 784)\n",
    "\n",
    "        # Activación Tanh para cada capa oculta\n",
    "        salida1 = torch.tanh(self.capa_oculta1(imagen_aplanada))\n",
    "        salida2 = torch.tanh(self.capa_oculta2(salida1))\n",
    "        salida3 = torch.tanh(self.capa_oculta3(salida2))\n",
    "\n",
    "        salida_final = self.capa_salida(salida3)\n",
    "\n",
    "        return salida_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9bc7f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Época número 6 iniciada.\n",
      "Época número 6 finalizada.\n",
      "\n",
      "Época número 7 iniciada.\n",
      "Época número 7 finalizada.\n",
      "\n",
      "Época número 8 iniciada.\n",
      "Época número 8 finalizada.\n",
      "\n",
      "Época número 9 iniciada.\n",
      "Época número 9 finalizada.\n",
      "\n",
      "Época número 10 iniciada.\n",
      "Época número 10 finalizada.\n",
      "\n",
      "Época número 11 iniciada.\n",
      "Época número 11 finalizada.\n",
      "\n",
      "Época número 12 iniciada.\n",
      "Época número 12 finalizada.\n",
      "\n",
      "Época número 13 iniciada.\n",
      "Época número 13 finalizada.\n",
      "\n",
      "Época número 14 iniciada.\n",
      "Época número 14 finalizada.\n",
      "\n",
      "Época número 15 iniciada.\n",
      "Época número 15 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 93.28 %\n"
     ]
    }
   ],
   "source": [
    "# Crear instancia del modelo 2\n",
    "modelo_dos = ModeloMLPProfundo()\n",
    "\n",
    "# Entrenar con 15 épocas y tasa de aprendizaje 0.005\n",
    "entrenar_modelo(modelo_dos, cargador_entrenamiento, cantidad_epocas=15, tasa_aprendizaje=0.005)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "precision_modelo2 = evaluar_modelo(modelo_dos, cargador_prueba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b23ef2",
   "metadata": {},
   "source": [
    " Parte 4.2 – Modelo 3: Una sola capa grande, activación Sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51413ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevo DataLoader para batch size 128\n",
    "cargador_entrenamiento_128 = DataLoader(dataset_entrenamiento, batch_size=128, shuffle=True)\n",
    "cargador_prueba_128 = DataLoader(dataset_prueba, batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ee7fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModeloMLPSimple(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo MLP con:\n",
    "    - Una única capa oculta de 512 neuronas\n",
    "    - Función de activación Sigmoid\n",
    "    - Capa de salida con 10 neuronas\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ModeloMLPSimple, self).__init__()\n",
    "\n",
    "        self.capa_oculta = nn.Linear(784, 512)\n",
    "        self.capa_salida = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, imagen):\n",
    "        imagen_aplanada = imagen.view(-1, 784)\n",
    "        activacion = torch.sigmoid(self.capa_oculta(imagen_aplanada))\n",
    "        salida = self.capa_salida(activacion)\n",
    "        return salida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f1486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época número 1 iniciada.\n",
      "Época número 1 finalizada.\n",
      "\n",
      "Época número 2 iniciada.\n",
      "Época número 2 finalizada.\n",
      "\n",
      "Época número 3 iniciada.\n",
      "Época número 3 finalizada.\n",
      "\n",
      "Época número 4 iniciada.\n",
      "Época número 4 finalizada.\n",
      "\n",
      "Época número 5 iniciada.\n",
      "Época número 5 finalizada.\n",
      "\n",
      "Época número 6 iniciada.\n",
      "Época número 6 finalizada.\n",
      "\n",
      "Época número 7 iniciada.\n",
      "Época número 7 finalizada.\n",
      "\n",
      "Época número 8 iniciada.\n",
      "Época número 8 finalizada.\n",
      "\n",
      "Época número 9 iniciada.\n",
      "Época número 9 finalizada.\n",
      "\n",
      "Época número 10 iniciada.\n",
      "Época número 10 finalizada.\n",
      "\n",
      "Época número 11 iniciada.\n",
      "Época número 11 finalizada.\n",
      "\n",
      "Época número 12 iniciada.\n",
      "Época número 12 finalizada.\n",
      "\n",
      "Precisión del modelo en el conjunto de prueba: 96.29 %\n"
     ]
    }
   ],
   "source": [
    "# Crear instancia del modelo 3\n",
    "modelo_tres = ModeloMLPSimple()\n",
    "\n",
    "# Entrenar con 12 épocas y learning rate 0.01\n",
    "entrenar_modelo(modelo_tres, cargador_entrenamiento_128, cantidad_epocas=12, tasa_aprendizaje=0.01)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "precision_modelo3 = evaluar_modelo(modelo_tres, cargador_prueba_128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557219e9",
   "metadata": {},
   "source": [
    " Lista de tareas pendientes (Laboratorio 3 – Deep Learning)\n",
    " - Tarea 1: Ejecutar el Modelo 3\n",
    " Correr el código del Modelo MLP 3 con activación sigmoid y una capa oculta de 512 neuronas.\n",
    "\n",
    " Esperar a que finalice el entrenamiento (12 épocas).\n",
    "\n",
    " Anotar la precisión (accuracy) que aparece en consola al final.\n",
    "\n",
    " - Tarea 2: Completar tabla comparativa de modelos\n",
    " Llenar una tabla con los datos de los tres modelos.\n",
    "\n",
    " Incluir:\n",
    "\n",
    "Capas ocultas\n",
    "\n",
    "Función de activación\n",
    "\n",
    "Número de épocas\n",
    "\n",
    "Learning rate\n",
    "\n",
    "Batch size\n",
    "\n",
    "Precisión obtenida\n",
    "\n",
    " Puedes hacer la tabla en Word, Excel, Google Docs o Jupyter Notebook.\n",
    "\n",
    " -  Tarea 3: Crear un ranking de rendimiento\n",
    " Ordenar los tres modelos de mejor a peor según su precisión.\n",
    "\n",
    " Escribir una lista tipo:\n",
    "\n",
    "1 Modelo con mayor precisión\n",
    "\n",
    "2 Segundo mejor\n",
    "\n",
    "3 Tercer lugar\n",
    "\n",
    " -  Tarea 4: Redactar respuesta a la pregunta del laboratorio\n",
    " Responder:\n",
    "\n",
    "¿Qué hiperparámetros influyeron más en la mejora del rendimiento del modelo? ¿Por qué?\n",
    "\n",
    " Escribir entre 5 y 10 líneas explicando cuál(es) hiperparámetro(s) fueron más importantes y por qué.\n",
    "\n",
    " -  Tarea 5 (Opcional): Aplicar tuning automático de hiperparámetros\n",
    " Elegir una técnica: Grid Search, Random Search o Bayesian Optimization\n",
    "\n",
    " Implementar la técnica para mejorar uno de los modelos (ej: Modelo 2)\n",
    "\n",
    " Comparar si se mejora la precisión\n",
    "\n",
    " Documentar los resultados (puedo ayudar si lo desean)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
